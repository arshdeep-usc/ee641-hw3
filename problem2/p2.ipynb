{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04b3573-67da-4256-a566-cc4c3d08a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sorting detection datasets...\n",
      "Training lengths: 8-16\n",
      "\n",
      "Training set:\n",
      "  Generated 10000 samples\n",
      "  Sorted: 4907 (49.1%)\n",
      "  Unsorted: 5093 (50.9%)\n",
      "  Average length: 12.0\n",
      "Saved 10000 samples to data/train.json\n",
      "\n",
      "Validation set:\n",
      "  Generated 2000 samples\n",
      "  Sorted: 1012 (50.6%)\n",
      "  Unsorted: 988 (49.4%)\n",
      "  Average length: 11.9\n",
      "Saved 2000 samples to data/val.json\n",
      "\n",
      "Test set:\n",
      "  Generated 2000 samples\n",
      "  Sorted: 1020 (51.0%)\n",
      "  Unsorted: 980 (49.0%)\n",
      "  Average length: 12.0\n",
      "Saved 2000 samples to data/test.json\n",
      "\n",
      "Example samples:\n",
      "  Sequence: [4, 9, 97, 48, 50, 51, 67, 99, 74, 88]...\n",
      "  Length: 14, Sorted: 0\n",
      "\n",
      "  Sequence: [88, 2, 25, 1, 24, 24, 50, 39, 47, 48]...\n",
      "  Length: 16, Sorted: 0\n",
      "\n",
      "  Sequence: [0, 96, 38, 26, 30, 72, 6, 45, 50, 54]...\n",
      "  Length: 16, Sorted: 0\n",
      "\n",
      "  Sequence: [7, 21, 31, 43, 56, 68, 76, 96, 97]\n",
      "  Length: 9, Sorted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./generate_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc46083-c3be-425f-aea6-7023688d9c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with sinusoidal positional encoding\n",
      "Output directory: results/sinusoidal\n",
      "Model parameters: 814,402\n",
      "/Users/robin/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Epoch 1/30\n",
      "Training: 100%|██████| 157/157 [00:06<00:00, 24.16it/s, loss=0.6992, acc=49.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 109.45it/s]\n",
      "Train Loss: 0.7286, Train Acc: 49.93%\n",
      "Val Loss: 1.3860, Val Acc: 50.60%\n",
      "Saved best model with validation accuracy: 50.60%\n",
      "\n",
      "Epoch 2/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.41it/s, loss=0.7080, acc=49.91%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 118.60it/s]\n",
      "Train Loss: 0.6934, Train Acc: 49.91%\n",
      "Val Loss: 1.3904, Val Acc: 49.40%\n",
      "\n",
      "Epoch 3/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.84it/s, loss=0.6944, acc=50.38%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 112.57it/s]\n",
      "Train Loss: 0.6934, Train Acc: 50.38%\n",
      "Val Loss: 1.3869, Val Acc: 49.40%\n",
      "\n",
      "Epoch 4/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 27.66it/s, loss=0.6939, acc=50.54%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 118.09it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.54%\n",
      "Val Loss: 1.3862, Val Acc: 50.60%\n",
      "\n",
      "Epoch 5/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 27.42it/s, loss=0.6942, acc=50.82%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 103.89it/s]\n",
      "Train Loss: 0.6932, Train Acc: 50.82%\n",
      "Val Loss: 1.3866, Val Acc: 49.40%\n",
      "\n",
      "Epoch 6/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 27.18it/s, loss=0.6917, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 111.13it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3869, Val Acc: 49.40%\n",
      "\n",
      "Epoch 7/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 27.27it/s, loss=0.6879, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 111.63it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 8/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.30it/s, loss=0.6912, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 108.74it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 9/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.45it/s, loss=0.6886, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 114.51it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 10/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.78it/s, loss=0.6934, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 119.72it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3875, Val Acc: 49.40%\n",
      "\n",
      "Epoch 11/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.39it/s, loss=0.6967, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.89it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 12/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.77it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 119.12it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 13/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.93it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 117.47it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 14/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.98it/s, loss=0.6952, acc=50.64%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 115.12it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.64%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 15/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.31it/s, loss=0.6915, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 114.92it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 16/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 31.13it/s, loss=0.6933, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 119.30it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 17/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.96it/s, loss=0.6851, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 123.63it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 18/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.92it/s, loss=0.6954, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 120.79it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 19/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.89it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:00<00:00, 99.25it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 20/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.10it/s, loss=0.6913, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 111.79it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 21/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.24it/s, loss=0.6982, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 117.88it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 22/30\n",
      "Training: 100%|██████| 157/157 [00:04<00:00, 31.45it/s, loss=0.6893, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 102.04it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 23/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.69it/s, loss=0.6956, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 108.87it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 24/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.47it/s, loss=0.6913, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 104.15it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 25/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.73it/s, loss=0.6887, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 108.76it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 26/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.21it/s, loss=0.6982, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 105.83it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 27/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.82it/s, loss=0.6932, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 105.05it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3869, Val Acc: 49.40%\n",
      "\n",
      "Epoch 28/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.85it/s, loss=0.6885, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 108.32it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "\n",
      "Epoch 29/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.77it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 112.80it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 30/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.62it/s, loss=0.6908, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 113.68it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3875, Val Acc: 49.40%\n",
      "/Users/robin/Desktop/EE 641/hw3/problem2/./train.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(output_dir / 'best_model.pth'))\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 109.45it/s]\n",
      "\n",
      "Test Loss: 1.3858, Test Acc: 51.00%\n",
      "\n",
      "Training complete! Results saved to results/sinusoidal\n"
     ]
    }
   ],
   "source": [
    "!python ./train.py --encoding=sinusoidal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4837273c-bca5-44df-b056-8034649beb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learned positional encoding\n",
      "Output directory: results/learned\n",
      "Model parameters: 852,802\n",
      "/Users/robin/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Epoch 1/30\n",
      "Training: 100%|██████| 157/157 [00:06<00:00, 24.57it/s, loss=0.6970, acc=50.19%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 104.28it/s]\n",
      "Train Loss: 0.7177, Train Acc: 50.19%\n",
      "Val Loss: 1.3902, Val Acc: 49.40%\n",
      "Saved best model with validation accuracy: 49.40%\n",
      "\n",
      "Epoch 2/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.13it/s, loss=0.7030, acc=51.00%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 118.58it/s]\n",
      "Train Loss: 0.6932, Train Acc: 51.00%\n",
      "Val Loss: 1.3877, Val Acc: 49.40%\n",
      "\n",
      "Epoch 3/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.43it/s, loss=0.6996, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 109.29it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 4/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.36it/s, loss=0.6858, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 116.97it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 5/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.38it/s, loss=0.6989, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 108.58it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 6/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.41it/s, loss=0.6933, acc=50.93%]\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:00<00:00, 94.46it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "\n",
      "Epoch 7/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.31it/s, loss=0.6874, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 108.47it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 8/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.48it/s, loss=0.6911, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 107.31it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 9/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.94it/s, loss=0.6955, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 106.05it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 10/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.66it/s, loss=0.6899, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 111.24it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 11/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.54it/s, loss=0.6867, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 107.26it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 12/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.40it/s, loss=0.6991, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 130.70it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3876, Val Acc: 49.40%\n",
      "\n",
      "Epoch 13/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.10it/s, loss=0.6986, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 107.79it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "\n",
      "Epoch 14/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.51it/s, loss=0.6934, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 113.04it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "\n",
      "Epoch 15/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.27it/s, loss=0.6934, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 113.92it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3876, Val Acc: 49.40%\n",
      "\n",
      "Epoch 16/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.28it/s, loss=0.6882, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 102.88it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3875, Val Acc: 49.40%\n",
      "\n",
      "Epoch 17/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.46it/s, loss=0.6956, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 114.68it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 18/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.35it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 115.83it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 19/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.32it/s, loss=0.6956, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 102.28it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 20/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.12it/s, loss=0.6978, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.39it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 21/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.27it/s, loss=0.6979, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 111.41it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 22/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.04it/s, loss=0.6911, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 109.03it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 23/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.40it/s, loss=0.6957, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.86it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 24/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.80it/s, loss=0.7015, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 114.66it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 25/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.18it/s, loss=0.6951, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 132.99it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 26/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.59it/s, loss=0.6885, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.65it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 27/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.94it/s, loss=0.6933, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 112.17it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 28/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.30it/s, loss=0.6933, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 114.14it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "\n",
      "Epoch 29/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.58it/s, loss=0.7000, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 114.76it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 30/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.35it/s, loss=0.7060, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 104.55it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "/Users/robin/Desktop/EE 641/hw3/problem2/./train.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(output_dir / 'best_model.pth'))\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 106.39it/s]\n",
      "\n",
      "Test Loss: 1.3906, Test Acc: 49.00%\n",
      "\n",
      "Training complete! Results saved to results/learned\n"
     ]
    }
   ],
   "source": [
    "!python ./train.py --encoding=learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70d8e47-a600-4d8d-bf5b-d3f20b49e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with none positional encoding\n",
      "Output directory: results/none\n",
      "Model parameters: 814,402\n",
      "/Users/robin/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Epoch 1/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 27.45it/s, loss=0.7190, acc=50.36%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 119.07it/s]\n",
      "Train Loss: 0.7240, Train Acc: 50.36%\n",
      "Val Loss: 1.3876, Val Acc: 50.60%\n",
      "Saved best model with validation accuracy: 50.60%\n",
      "\n",
      "Epoch 2/30\n",
      "Training: 100%|██████| 157/157 [00:04<00:00, 31.85it/s, loss=0.7143, acc=49.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 119.83it/s]\n",
      "Train Loss: 0.6937, Train Acc: 49.93%\n",
      "Val Loss: 1.3926, Val Acc: 49.40%\n",
      "\n",
      "Epoch 3/30\n",
      "Training: 100%|██████| 157/157 [00:04<00:00, 31.98it/s, loss=0.6951, acc=49.88%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 117.79it/s]\n",
      "Train Loss: 0.6935, Train Acc: 49.88%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 4/30\n",
      "Training: 100%|██████| 157/157 [00:04<00:00, 31.62it/s, loss=0.6947, acc=50.81%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 119.65it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.81%\n",
      "Val Loss: 1.3861, Val Acc: 50.60%\n",
      "\n",
      "Epoch 5/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 31.23it/s, loss=0.6930, acc=49.87%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 121.33it/s]\n",
      "Train Loss: 0.6934, Train Acc: 49.87%\n",
      "Val Loss: 1.3862, Val Acc: 50.60%\n",
      "\n",
      "Epoch 6/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.25it/s, loss=0.6921, acc=50.48%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 116.32it/s]\n",
      "Train Loss: 0.6932, Train Acc: 50.48%\n",
      "Val Loss: 1.3867, Val Acc: 49.40%\n",
      "\n",
      "Epoch 7/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 31.16it/s, loss=0.6894, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 120.43it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3868, Val Acc: 49.40%\n",
      "\n",
      "Epoch 8/30\n",
      "Training: 100%|██████| 157/157 [00:04<00:00, 32.47it/s, loss=0.6913, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 120.57it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 9/30\n",
      "Training: 100%|██████| 157/157 [00:04<00:00, 31.82it/s, loss=0.6887, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 120.39it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 10/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.31it/s, loss=0.6934, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 121.39it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3875, Val Acc: 49.40%\n",
      "\n",
      "Epoch 11/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.87it/s, loss=0.6967, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 113.36it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 12/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.79it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 113.40it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 13/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.93it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 100.38it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 14/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.80it/s, loss=0.6950, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 106.12it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 15/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.36it/s, loss=0.6915, acc=50.93%]\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:00<00:00, 96.48it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 16/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 27.07it/s, loss=0.6933, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.07it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3870, Val Acc: 49.40%\n",
      "\n",
      "Epoch 17/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.85it/s, loss=0.6851, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 112.83it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 18/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.03it/s, loss=0.6954, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 100.09it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 19/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.68it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 105.34it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 20/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.56it/s, loss=0.6913, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 112.81it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 21/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.39it/s, loss=0.6982, acc=50.93%]\n",
      "Evaluating: 100%|███████████████████████████████| 32/32 [00:00<00:00, 99.29it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 22/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.57it/s, loss=0.6893, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 113.32it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 23/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.60it/s, loss=0.6956, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 109.79it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3872, Val Acc: 49.40%\n",
      "\n",
      "Epoch 24/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.06it/s, loss=0.6913, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 111.71it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3871, Val Acc: 49.40%\n",
      "\n",
      "Epoch 25/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.05it/s, loss=0.6887, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.65it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 26/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 28.87it/s, loss=0.6982, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 116.70it/s]\n",
      "Train Loss: 0.6931, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 27/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.27it/s, loss=0.6932, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 112.36it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3869, Val Acc: 49.40%\n",
      "\n",
      "Epoch 28/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.59it/s, loss=0.6885, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 115.50it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3874, Val Acc: 49.40%\n",
      "\n",
      "Epoch 29/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 29.75it/s, loss=0.6910, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 131.73it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3873, Val Acc: 49.40%\n",
      "\n",
      "Epoch 30/30\n",
      "Training: 100%|██████| 157/157 [00:05<00:00, 30.40it/s, loss=0.6908, acc=50.93%]\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 120.56it/s]\n",
      "Train Loss: 0.6930, Train Acc: 50.93%\n",
      "Val Loss: 1.3875, Val Acc: 49.40%\n",
      "/Users/robin/Desktop/EE 641/hw3/problem2/./train.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(output_dir / 'best_model.pth'))\n",
      "Evaluating: 100%|██████████████████████████████| 32/32 [00:00<00:00, 110.45it/s]\n",
      "\n",
      "Test Loss: 1.3870, Test Acc: 51.00%\n",
      "\n",
      "Training complete! Results saved to results/none\n"
     ]
    }
   ],
   "source": [
    "!python ./train.py --encoding=none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2648d38b-8429-4744-8e19-86ca527ae04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sorting detection datasets...\n",
      "Training lengths: 8-16\n",
      "\n",
      "Training set:\n",
      "  Generated 10000 samples\n",
      "  Sorted: 4907 (49.1%)\n",
      "  Unsorted: 5093 (50.9%)\n",
      "  Average length: 12.0\n",
      "Saved 10000 samples to data/train.json\n",
      "\n",
      "Validation set:\n",
      "  Generated 2000 samples\n",
      "  Sorted: 1012 (50.6%)\n",
      "  Unsorted: 988 (49.4%)\n",
      "  Average length: 11.9\n",
      "Saved 2000 samples to data/val.json\n",
      "\n",
      "Test set:\n",
      "  Generated 2000 samples\n",
      "  Sorted: 1020 (51.0%)\n",
      "  Unsorted: 980 (49.0%)\n",
      "  Average length: 12.0\n",
      "Saved 2000 samples to data/test.json\n",
      "\n",
      "Generating extrapolation test sets...\n",
      "\n",
      "Generating extrapolation set for length 32...\n",
      "  Generated 500 samples\n",
      "  Sorted: 227 (45.4%)\n",
      "  Unsorted: 273 (54.6%)\n",
      "  Average length: 32.0\n",
      "\n",
      "Generating extrapolation set for length 64...\n",
      "  Generated 500 samples\n",
      "  Sorted: 257 (51.4%)\n",
      "  Unsorted: 243 (48.6%)\n",
      "  Average length: 64.0\n",
      "\n",
      "Generating extrapolation set for length 128...\n",
      "  Generated 500 samples\n",
      "  Sorted: 259 (51.8%)\n",
      "  Unsorted: 241 (48.2%)\n",
      "  Average length: 128.0\n",
      "\n",
      "Generating extrapolation set for length 256...\n",
      "  Generated 500 samples\n",
      "  Sorted: 256 (51.2%)\n",
      "  Unsorted: 244 (48.8%)\n",
      "  Average length: 256.0\n",
      "Saved 500 samples to data/extrapolation/test_len_32.json\n",
      "Saved 500 samples to data/extrapolation/test_len_64.json\n",
      "Saved 500 samples to data/extrapolation/test_len_128.json\n",
      "Saved 500 samples to data/extrapolation/test_len_256.json\n",
      "\n",
      "Example samples:\n",
      "  Sequence: [4, 9, 97, 48, 50, 51, 67, 99, 74, 88]...\n",
      "  Length: 14, Sorted: 0\n",
      "\n",
      "  Sequence: [88, 2, 25, 1, 24, 24, 50, 39, 47, 48]...\n",
      "  Length: 16, Sorted: 0\n",
      "\n",
      "  Sequence: [0, 96, 38, 26, 30, 72, 6, 45, 50, 54]...\n",
      "  Length: 16, Sorted: 0\n",
      "\n",
      "  Sequence: [7, 21, 31, 43, 56, 68, 76, 96, 97]\n",
      "  Length: 9, Sorted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./generate_data.py --generate-extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10b9fd80-3e6a-4b04-a3dd-41a8d21dc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing sinusoidal encoding\n",
      "==================================================\n",
      "/Users/robin/Desktop/EE 641/hw3/problem2/./analyze.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "Testing on length 32...\n",
      "Length 32: 100%|████████████████████████████████| 16/16 [00:00<00:00, 19.27it/s]\n",
      "  Accuracy: 45.40%\n",
      "Testing on length 64...\n",
      "Length 64: 100%|████████████████████████████████| 16/16 [00:00<00:00, 42.91it/s]\n",
      "  Accuracy: 51.40%\n",
      "Testing on length 128...\n",
      "Length 128: 100%|███████████████████████████████| 16/16 [00:00<00:00, 51.94it/s]\n",
      "  Accuracy: 51.80%\n",
      "Testing on length 256...\n",
      "Length 256: 100%|███████████████████████████████| 16/16 [00:00<00:00, 26.37it/s]\n",
      "  Accuracy: 51.20%\n",
      "\n",
      "==================================================\n",
      "Testing learned encoding\n",
      "==================================================\n",
      "Testing on length 32...\n",
      "Length 32: 100%|███████████████████████████████| 16/16 [00:00<00:00, 153.31it/s]\n",
      "  Accuracy: 54.60%\n",
      "Testing on length 64...\n",
      "Length 64: 100%|███████████████████████████████| 16/16 [00:00<00:00, 119.16it/s]\n",
      "  Accuracy: 48.60%\n",
      "Testing on length 128...\n",
      "Length 128: 100%|███████████████████████████████| 16/16 [00:00<00:00, 84.86it/s]\n",
      "  Accuracy: 48.20%\n",
      "Testing on length 256...\n",
      "Length 256: 100%|███████████████████████████████| 16/16 [00:00<00:00, 42.40it/s]\n",
      "  Accuracy: 48.80%\n",
      "\n",
      "==================================================\n",
      "Testing none encoding\n",
      "==================================================\n",
      "Testing on length 32...\n",
      "Length 32: 100%|███████████████████████████████| 16/16 [00:00<00:00, 180.22it/s]\n",
      "  Accuracy: 45.40%\n",
      "Testing on length 64...\n",
      "Length 64: 100%|███████████████████████████████| 16/16 [00:00<00:00, 143.48it/s]\n",
      "  Accuracy: 51.40%\n",
      "Testing on length 128...\n",
      "Length 128: 100%|███████████████████████████████| 16/16 [00:00<00:00, 93.66it/s]\n",
      "  Accuracy: 51.80%\n",
      "Testing on length 256...\n",
      "Length 256: 100%|███████████████████████████████| 16/16 [00:00<00:00, 41.85it/s]\n",
      "  Accuracy: 51.20%\n",
      "Figure(1000x600)\n",
      "Saved extrapolation curves to results/extrapolation/extrapolation_curves.png\n",
      "/Users/robin/Desktop/EE 641/hw3/problem2/./analyze.py:134: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
      "Figure(1200x800)\n",
      "Figure(1200x800)\n",
      "Saved position embeddings visualization to results/extrapolation/position_viz/learned_position_embeddings.png\n",
      "Figure(1500x500)\n",
      "Saved encoding comparison to results/extrapolation/encoding_comparison/encoding_comparison.png\n",
      "\n",
      "==================================================\n",
      "Analyzing failure cases for learned encoding at length 64\n",
      "==================================================\n",
      "/Users/robin/Desktop/EE 641/hw3/problem2/./analyze.py:352: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\n",
      "\n",
      "Analyzing 10 failure cases:\n",
      "\n",
      "Example 1:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 0  1  1  3  3  5  7  9 13 19]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.35%\n",
      "\n",
      "Example 2:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 4  4  5  7  9 11 14 17 20 20]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.36%\n",
      "\n",
      "Example 3:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 0  0  1  2  2  3  3  6 10 14]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.36%\n",
      "\n",
      "Example 4:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 1  3  6  6  6  7  8  9 10 12]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.35%\n",
      "\n",
      "Example 5:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 3  7  8 12 13 16 22 23 28 28]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.35%\n",
      "\n",
      "Example 6:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 0  1  2  2  2  3  6 10 10 12]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.35%\n",
      "\n",
      "Example 7:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 2  2  2  4  4  5 10 11 17 17]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.35%\n",
      "\n",
      "Example 8:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 0  1  2  3  5  5  6  7  8 10]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.35%\n",
      "\n",
      "Example 9:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 1  8 12 12 13 14 15 19 19 21]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.37%\n",
      "\n",
      "Example 10:\n",
      "  Length: 64\n",
      "  Sequence (first 10): [ 2  2  3  5  6  7  8  9  9 11]...\n",
      "  True label: Sorted\n",
      "  Predicted: Unsorted\n",
      "  Confidence: 52.36%\n",
      "\n",
      "Analysis complete! Results saved to results/extrapolation\n"
     ]
    }
   ],
   "source": [
    "!python ./analyze.py --test-lengths 32 64 128 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d2ea6-363e-4053-a46a-e5df8968788f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
